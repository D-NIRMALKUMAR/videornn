{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">226,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">452,867</span> │\n",
       "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional (\u001b[38;5;33mFunctional\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m) │       \u001b[38;5;34m226,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,   │       \u001b[38;5;34m452,867\u001b[0m │\n",
       "│                                 │ \u001b[38;5;34m3\u001b[0m)                     │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">679,427</span> (2.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m679,427\u001b[0m (2.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">679,427</span> (2.59 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m679,427\u001b[0m (2.59 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m455s\u001b[0m 5s/step - loss: 0.0477\n",
      "Epoch 2/10\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 5s/step - loss: 0.0135\n",
      "Epoch 3/10\n",
      "\u001b[1m11/97\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:57\u001b[0m 7s/step - loss: 0.0040 "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the encoder\n",
    "def create_encoder(input_shape):\n",
    "    encoder_input = tf.keras.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Conv3D(64, (3, 3, 3), activation='relu', padding='same')(encoder_input)\n",
    "    x = tf.keras.layers.MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "    encoder_output = tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "    return tf.keras.Model(encoder_input, encoder_output)\n",
    "\n",
    "# Define the decoder\n",
    "def create_decoder(encoded_shape):\n",
    "    decoder_input = tf.keras.Input(shape=encoded_shape)\n",
    "    x = tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu', padding='same')(decoder_input)\n",
    "    x = tf.keras.layers.UpSampling3D((2, 2, 2))(x)\n",
    "    decoder_output = tf.keras.layers.Conv3D(3, (3, 3, 3), activation='sigmoid', padding='same')(x)\n",
    "    return tf.keras.Model(decoder_input, decoder_output)\n",
    "\n",
    "# Combine encoder and decoder\n",
    "input_shape = (16, 128, 128, 3)  # Example input shape\n",
    "encoder = create_encoder(input_shape)\n",
    "encoded_shape = encoder.output_shape[1:]\n",
    "decoder = create_decoder(encoded_shape)\n",
    "\n",
    "autoencoder_input = tf.keras.Input(shape=input_shape)\n",
    "encoded = encoder(autoencoder_input)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "autoencoder = tf.keras.Model(autoencoder_input, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Summary of the model\n",
    "autoencoder.summary()\n",
    "\n",
    "# Function to load and preprocess videos\n",
    "def load_videos(folder, frame_size, frame_count):\n",
    "    frames = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith('.avi'):\n",
    "            cap = cv2.VideoCapture(os.path.join(folder, filename))\n",
    "            video_frames = []\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                frame = cv2.resize(frame, frame_size)\n",
    "                video_frames.append(frame)\n",
    "                if len(video_frames) == frame_count:\n",
    "                    frames.append(video_frames)\n",
    "                    video_frames = []\n",
    "            cap.release()\n",
    "    frames = np.array(frames)\n",
    "    frames = frames / 255.0  # Normalize\n",
    "    return frames\n",
    "\n",
    "# Load and preprocess videos\n",
    "frame_size = (128, 128)\n",
    "frame_count = 16\n",
    "video_frames = load_videos('h1/brush_hair', frame_size, frame_count)\n",
    "\n",
    "# Train the autoencoder\n",
    "autoencoder.fit(video_frames, video_frames, epochs=10, batch_size=1)\n",
    "\n",
    "# Encode and decode video frames\n",
    "encoded_frames = encoder.predict(video_frames)\n",
    "decoded_frames = decoder.predict(encoded_frames)\n",
    "\n",
    "# Function to save video\n",
    "def save_video(filename, frames, frame_size):\n",
    "    height, width = frame_size\n",
    "    video = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
    "    for frame_set in frames:\n",
    "        for frame in frame_set:\n",
    "            frame = (frame * 255).astype(np.uint8)\n",
    "            video.write(frame)\n",
    "    video.release()\n",
    "\n",
    "# Save reconstructed video\n",
    "save_video('reconstructed_cat.mp4', decoded_frames, frame_size)\n",
    "\n",
    "print(\"Video processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "autoencoder.save('g.h5')\n",
    "encoder.save('e.h5')\n",
    "decoder.save('d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 13s/step\n",
      "Video processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Encode and decode video frames\n",
    "encoded_frames = encoder.predict(video_frames)\n",
    "decoded_frames = decoder.predict(encoded_frames)\n",
    "\n",
    "# Function to save video\n",
    "def save_video(filename, frames, frame_size):\n",
    "    height, width = frame_size\n",
    "    video = cv2.VideoWriter(filename, cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n",
    "    for frame_set in frames:\n",
    "        for frame in frame_set:\n",
    "            frame = (frame * 255).astype(np.uint8)\n",
    "            video.write(frame)\n",
    "    video.release()\n",
    "\n",
    "# Save reconstructed video\n",
    "save_video('reconstructed_cat.mp4', decoded_frames, frame_size)\n",
    "\n",
    "print(\"Video processing complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
