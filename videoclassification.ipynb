{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load videos from the folder\n",
    "def load_videos_from_folder(folder_path):\n",
    "    videos = []\n",
    "    labels = []\n",
    "    \n",
    "    # List all action categories\n",
    "    action_labels = os.listdir(folder_path)\n",
    "    \n",
    "    for label in action_labels:\n",
    "        action_folder = os.path.join(folder_path, label)\n",
    "        for video_file in os.listdir(action_folder):\n",
    "            if video_file.endswith('.avi'):  # Assuming videos are in .avi format\n",
    "                video_path = os.path.join(action_folder, video_file)\n",
    "                videos.append(video_path)\n",
    "                labels.append(label)  # Store the corresponding label\n",
    "                \n",
    "    return videos, labels\n",
    "\n",
    "# Preprocess the video\n",
    "def preprocess_video(video_path, num_frames=30, img_size=(224, 224)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    if total_frames == 0:\n",
    "        print(f\"Warning: No frames found in video {video_path}\")\n",
    "        return np.array([])  # Return an empty array if no frames are found\n",
    "\n",
    "    step = total_frames // num_frames\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i * step)  # Set the frame position\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Could not read frame {i} from video {video_path}\")\n",
    "            break\n",
    "        frame = cv2.resize(frame, img_size)  # Resize frame\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "# Create dataset\n",
    "def create_dataset(video_paths, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    label_mapping = {label: idx for idx, label in enumerate(set(labels))}\n",
    "    \n",
    "    for video_path, label in zip(video_paths, labels):\n",
    "        frames = preprocess_video(video_path)\n",
    "        if frames.shape[0] > 0:\n",
    "            X.append(frames)\n",
    "            y.append(label_mapping[label])  # Convert label to numerical format\n",
    "            \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Build the model\n",
    "def build_model(num_classes):\n",
    "    base_model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "    base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "    # Define a feature extractor\n",
    "    def feature_extractor(x):\n",
    "        return base_model(x)\n",
    "\n",
    "    # Input layer for the sequence of frames\n",
    "    inputs = layers.Input(shape=(30, 224, 224, 3))\n",
    "    x = layers.TimeDistributed(layers.Lambda(feature_extractor))(inputs)\n",
    "    x = layers.TimeDistributed(layers.GlobalAveragePooling2D())(x)\n",
    "    x = layers.LSTM(64)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Load and preprocess dataset\n",
    "video_folder_path = 'h1'  # Replace with the path to your HMDB51 dataset\n",
    "video_paths, labels = load_videos_from_folder(video_folder_path)\n",
    "X, y = create_dataset(video_paths, labels)\n",
    "\n",
    "# Normalize the data\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and compile the model\n",
    "num_classes = len(set(y))\n",
    "model = build_model(num_classes)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "# Classify a new video\n",
    "def classify_video(video_path, model):\n",
    "    frames = preprocess_video(video_path)\n",
    "    if frames.size == 0:\n",
    "        print(\"Error: No frames to classify.\")\n",
    "        return None\n",
    "    \n",
    "    frames = frames.astype('float32') / 255.0\n",
    "    frames = np.expand_dims(frames, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(frames)\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    return predicted_class\n",
    "\n",
    "# Example usage of classify_video\n",
    "new_video_path = 'HMDB_dataset/brush_hair/testing_1.avi'  # Replace with your video path\n",
    "if not os.path.isfile(new_video_path):\n",
    "    print(f\"Error: The video file {new_video_path} does not exist.\")\n",
    "else:\n",
    "    print(\"Predicted Class:\", classify_video(new_video_path, model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
